# Intro to Prompt Engineering

Lecture: https://www.youtube.com/watch?v=dOxUroR57xs

## Notes

### Why
- Important for research, discoveries, and advancement
- Helps to test and evaluate the limitations of LLMs
- Enables all kinds of innovative applications

### First basic prompt: “The sky is blue”

- Model
- Temperature
- top-p

### Elements of a prompt

- Instructions — neutral / negative / positive
- Context
- Input data
- Output indicator (sentiment)

### Settings to keep in mind

- Get different results with prompts when using different settings
- Controlling how deterministic the model is when generating completion for prompts
- Temperature and top_p are two important parameters to keep in mind
- Generally, keep these low if you arel ooking for exact answers
- Keep them high if you are looking for more diverse responses

### Designing prompts for different tasks

Categories:
- Text Summarization
- Question Answering
- Text Classification
- Role Playing
- Code Generation
- Reasoning

### Prompt Examples

- Text Summarization: "Explain the above in one sentence" (instruction; concise or precise way)
- Question Answering: Instruction => Context => Question.
- Text Classification: "Classify the text into neutral, negative, or positive."
- Role Playing: "Behave in a certain way - let the tone be technical and scientific."
- Code Generation: "Write a function that takes in a number and returns the square of that number."
- Reasoning: "Explain why the above is true."
    - If these AIs can go about reasoning, this is a huge step forward in combining seemingly disparate contexts and drawing a new conclusion from them that isn't yet written.

### Prompt Engineering Techniques

- Few shot prompts: allows us to provide **exemplars** in prompts to seter the model towards better performance. Give it an idea of what the task is about, and follow the pattern of the exemplars. It's like how I learn what to do and apply in new situations (what have we done before, and given those patterns, how can I apply it here?)
- Chain of thought prompting: Prompting can be further improved by instructing the model to reason about the task when responding.
  - Very useful tor tasks that require reasoning
  - You can combine it with few-shot prompting to get better results
  - You can also do zero-shot CoT where exemplats are not available
    - Involves adding "Let's think step by step" to the original prompt
      - Large Language Models are Zero-shot Reasoners (!!)
- Self consistency: aims to improve on the naive greedy decoding used in chain-of-thought prompting
  - The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to select the most consistent answer
  - This helps to boost the performance of CoT prompting on thsks involving arithmetic and common-sense reasoning
- Knowledge generation prompting
  - This technique involves using additional knowledge provided as part of the context to improve results on complex tasksssuch as commonsense reasoning
  - The knowledge used in the context is generated by a model and used in the prompt to make a prediction; highest-confidence prediction is used
  - Example: The first step is to generate knowledge. Give it a prompt template. Then, give it a context. The context is the knowledge that the model generates. Then, give it a question. The model will answer the question based on the knowledge that it generated. Explain and answer is the key here.
- ReAct = Reason + Act
  - Framework where LLMs are used to generate both reasoning traces and task-specific actions in an interleaved manner
  - Generating reasoning traces allow the model to incude, track, and update action plans, and even handle exceptions
  - The action step allows to interface with and gather information from external sources such as knowledge bases or environments
  - In other words: this allows LLMs to interact with external tools to retrieve additional information that leads to more reliable and factual responses.
- Program-aided language model (PAL)
  - Chain-of-thought prompting is a good example of how to steer models to perform better at complex reasoning tasks
    - However, sometimes CoT is not enough as it depends only on the generated text from the model
  - Program-aided langauge models (PAL) uses an LLM to read problems and generate programs as the intermediate reasoning steps; it offloads the solution step to a runtime such as Python interpreter


### Zero-shot CoT Example

```python
prompt = """
I went to the market and bought 10 apples.
I gave 2 apples to the neighbor and 2 to the repairman.
I then went and bought 5 more apples and ate 1.
How many apples did I remain with?

Let's think step by step."""

response = get_completion(params, prompt)
IPython.display.Markdown(response.choices[0].text)
```

- Reduce the stereotype bias by provide a very precise prompt

### Data-augmented generation

- It's important to get the most up-to-date information for the model so you can get the most accurate results
- Process and instructions can be perfect, but again -- if the data coming isn't accurate, then the results won't be accurate
- There's a way to short-circuit: explain that it doesn't need to provide answer if it doesn't know, don't make one up. Also, having a way to say "source" is good to build confidence.

### Closing thoughts

#### Model Safety

- Prompt engineering can be used not only to improve performance but also the reliability of response from a safety perspective
  - Prompt engineering can help identify risky behaviours of LLMs which can help to reduce harmful behaviors and risks that may arise from language models
  - There is also a part of the community performing prompt injection to understand the vulnerability of LLMs

#### Prompt Injections

- Prompt injection is used to hijack an LM's output by injecting an untrusted command that overrides instruction of a prompt
  - This could easily happen if you just concatenate your prompt with another user generated prompt
- Prompt leaking: afrce the model to spit out information about its own prompt
  - This can lead to leaking of either sensitive, private, or information that's confidential
- Jailbreaking: form of prompt injection where the goal is to bypass safety and moderation features
  - LLMs provided via APIs might be coupled with safety features or content moderation which can be bypassed with harmful prompts/attacks
  - This might sound like a difficult task but it's not because the model is usually served static and might have these vulnerabilities due to many factors such as where data has been trained on
- RLHF: Reinforcement Learning from Human feedback: now being used to train LLMs that f it human preference
  - RLHF: involves collecting high-quality prompt datasets
  - Examples: Claude (Anthropic); ChatGPT (OpenAI)

#### Future Directions

- Augmented LMs
- Emergent ability of LMs
- Acting / Planning - Reinforcement Learning
- Multimodal Prompting
- Graph Prompting

### Questions / Next steps

Find the answers:
- On classification: are there other things that you can classify on besides neutral, negative, and positive? I need five examples.
- On `Data-augmented generation`: how can I get started? Is there a tool or playground for this?
  - https://docs.langchain.com/docs/

Do the work:
  - Do all the exercises and write a blog post about it
  - Watch [Sparks of AGI: early experiments with GPT-4](https://youtu.be/qbIk7-JPB2c)
